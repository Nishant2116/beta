import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

df = pd.read_csv("google_stock_prices.csv")
df

# Extract Close prices
data = df['Close'].values.reshape(-1, 1)

# Step 3: Preprocess the Data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Create sequences for input to RNN
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)


seq_length = 20  # Number of time steps to look back
X, y = create_sequences(scaled_data, seq_length)


# Split data into training and testing sets
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]


model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    LSTM(units=50, return_sequences=False),
    Dense(units=1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10)


test_loss = model.evaluate(X_test, y_test)
print('Test Loss:', test_loss)


predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)


plt.figure(figsize=(12, 6))
plt.plot(df.index[split+seq_length:], df['Close'][split+seq_length:], label='Actual Prices')
plt.plot(df.index[split+seq_length:], predictions, label='Predicted Prices')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Google Stock Prices - Actual vs Predicted')
plt.legend()
plt.show()